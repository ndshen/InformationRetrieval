{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM_Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries/Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from pymongo import MongoClient\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "import math\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database arguments\n",
    "HOST = '140.112.107.203'\n",
    "PORT = 27020\n",
    "USERNAME = 'rootNinja'\n",
    "PASSWORD = ''\n",
    "DBNAME = 'IR_final'\n",
    "collections = ['Boy-Girl', 'C_Chat', 'HatePolitics', 'Movie', 'NBA', 'Stock']\n",
    "\n",
    "dictionary_file = 'dictionary.txt'\n",
    "accept_tags = {'nz', 'nt', 'nrt', 'nrfg', 'nr', 'n', 'a'}\n",
    "\n",
    "train_num = 100\n",
    "content_length_threshold = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_DB():\n",
    "    \"\"\"Connect to mongo database and return the database\"\"\"\n",
    "    client = MongoClient()\n",
    "    client=MongoClient(host=HOST,port=PORT,username=USERNAME,password=PASSWORD)\n",
    "    db=client[DBNAME]\n",
    "    return(db)\n",
    "\n",
    "def load_dictionary(txt_file):\n",
    "    result = []\n",
    "    with open(txt_file, 'r', encoding=\"utf-8\") as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        for line in lines:\n",
    "            result.append(line)\n",
    "    return(result)\n",
    "\n",
    "def extract_terms(document:str):\n",
    "    content = document.replace('\\n','')\n",
    "    words = pseg.cut(content)\n",
    "    final_token_list = [word for word, tag in words if tag in accept_tags and len(word) > 1]\n",
    "    return(final_token_list)\n",
    "\n",
    "def doc_to_vector(document:str, dictionary:list, dimension:int):\n",
    "    token_list = extract_terms(document)\n",
    "    article_vector = [0 for j in range(dimension)]\n",
    "    vector_sum = 0\n",
    "    for token in token_list:\n",
    "        if token in dictionary:\n",
    "            article_vector[dictionary.index(token)] += 1\n",
    "            vector_sum += 1\n",
    "    if vector_sum == 0:\n",
    "        normed_article_vector = article_vector\n",
    "    else:\n",
    "        magnitude = math.sqrt(sum(map(lambda x: x**2, article_vector)))\n",
    "        normed_article_vector = list(map(lambda x: x/magnitude, article_vector))\n",
    "    return(normed_article_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = connect_to_DB()\n",
    "dictionary = load_dictionary(dictionary_file)\n",
    "dimension = len(dictionary)\n",
    "training = []\n",
    "for collection_name in collections:\n",
    "    c = db[collection_name]\n",
    "    print(\"Doing {}\".format(collection_name))\n",
    "    done = 0\n",
    "    for i, article in enumerate(c.find(no_cursor_timeout=True, batch_size=30)):\n",
    "        if len(article['Content']) > content_length_threshold:\n",
    "            training.append(doc_to_vector(article['Content'], dictionary, dimension))\n",
    "            done += 1\n",
    "            print('Done: {}'.format(done), end='\\r')\n",
    "            if done == train_num:\n",
    "                break\n",
    "            \n",
    "training_x = np.array(training)\n",
    "training_y = np.zeros(train_num*len(collections))\n",
    "for i in range(len(collections)):\n",
    "    training_y[i*train_num:(i+1)*train_num] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 'scale'\n",
    "clf = svm.SVC(gamma=g, decision_function_shape='ovr')\n",
    "clf.fit(training_x, training_y)\n",
    "dump(clf, 'svm_linear2.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(document:str, dictionary, clf):\n",
    "    doc_vec = doc_to_vector(document, dictionary, len(dictionary))\n",
    "    dec = clf.decision_function([doc_vec])\n",
    "    # print(dec)\n",
    "    answer = collections[np.argmax(dec.flatten())]\n",
    "    return(answer)\n",
    "\n",
    "db = connect_to_DB()\n",
    "dictionary = load_dictionary(dictionary_file)\n",
    "model = load('svm_linear2.joblib')\n",
    "test_num = 100\n",
    "error = 0\n",
    "\n",
    "for collection_name in collections:\n",
    "    c = db[collection_name]\n",
    "    print(\"Doing {}\".format(collection_name))\n",
    "    done = 0\n",
    "    for i, article in enumerate(c.find(no_cursor_timeout=True, batch_size=30).sort(\"id\", -1)):\n",
    "\n",
    "        if len(article['Content']) > content_length_threshold:\n",
    "            if classify(article['Content'], dictionary, model) != collection_name:\n",
    "                error += 1\n",
    "\n",
    "            done += 1\n",
    "            print('Done: {}'.format(done), end='\\r')\n",
    "            if done == test_num:\n",
    "                break\n",
    "print()\n",
    "print(\"error: {}\".format(error))\n",
    "print(\"accuracy: {}\".format(error/test_num*6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
